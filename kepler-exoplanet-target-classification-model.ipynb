{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/dascient/kepler-exoplanet-classification-model?scriptVersionId=144909782\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Kepler Data Analysis","metadata":{}},{"cell_type":"code","source":"# lets begin!\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier \nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\n# for the sake of expeditious analysis\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nfrom shapely.geometry import Point\nimport geopandas as gpd\nfrom wordcloud import WordCloud, STOPWORDS\nfrom geopandas import GeoDataFrame\nimport matplotlib.colors as colors\nimport seaborn as sns\nimport random as r\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# kepler labled test & train\nexoTest = pd.read_csv('/kaggle/input/kepler-labelled-time-series-data/exoTest.csv',header=0)\nexoTrain = pd.read_csv('/kaggle/input/kepler-labelled-time-series-data/exoTrain.csv',header=0)\ncumulative = pd.read_csv('/kaggle/input/kepler-exoplanet-search-results/cumulative.csv',header=0)\ncomposite = pd.read_csv(\"/kaggle/input/httpsexoplanetarchive-ipac-caltech-edu/PSCompPars_2023.09.30_20.49.04.csv\",header=168)#,error_bad_lines=False)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-01T23:41:00.017237Z","iopub.execute_input":"2023-10-01T23:41:00.017691Z","iopub.status.idle":"2023-10-01T23:41:09.966478Z","shell.execute_reply.started":"2023-10-01T23:41:00.01763Z","shell.execute_reply":"2023-10-01T23:41:09.965336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_columns', None)\ncomposite.discoverymethod.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T05:08:13.51325Z","iopub.execute_input":"2023-10-01T05:08:13.513703Z","iopub.status.idle":"2023-10-01T05:08:13.525272Z","shell.execute_reply.started":"2023-10-01T05:08:13.513666Z","shell.execute_reply":"2023-10-01T05:08:13.523877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Multidimensional ExoPlots","metadata":{}},{"cell_type":"code","source":"import plotly.express as px\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\n\n# graph\nfig = px.scatter_3d(composite, x='elat', y='elon', z='glat',\n              color='disc_year',\n              size = 'ra',\n              hover_name = 'hostname',\n              hover_data=['disc_locale','disc_telescope','gaia_id','hd_name','disc_facility'],              \n              opacity=0.5,\n              size_max=25\n                   )\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:56:33.701775Z","iopub.execute_input":"2023-10-01T04:56:33.702189Z","iopub.status.idle":"2023-10-01T04:56:35.276439Z","shell.execute_reply.started":"2023-10-01T04:56:33.702142Z","shell.execute_reply":"2023-10-01T04:56:35.274916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\n\n# graph\nfig = px.scatter_3d(composite, x='elat', y='elon', z='glon',\n              color='disc_year',\n              size = 'ra',\n              hover_name = 'hostname',\n              hover_data=['disc_locale','disc_telescope','gaia_id','hd_name','disc_facility'],              \n              opacity=0.5,\n              size_max=25\n                   )\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:56:35.280476Z","iopub.execute_input":"2023-10-01T04:56:35.281504Z","iopub.status.idle":"2023-10-01T04:56:35.539104Z","shell.execute_reply.started":"2023-10-01T04:56:35.281444Z","shell.execute_reply":"2023-10-01T04:56:35.538092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# datasets\n#exoTest.describe()#.style.background_gradient(cmap ='coolwarm').set_properties(**{'font-size': '8px'})\n#exoTrain.describe()#.style.background_gradient(cmap ='coolwarm').set_properties(**{'font-size': '8px'})\n#cumulative.describe()#.style.background_gradient(cmap ='coolwarm').set_properties(**{'font-size': '8px'})","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:56:35.540508Z","iopub.execute_input":"2023-10-01T04:56:35.541346Z","iopub.status.idle":"2023-10-01T04:56:35.545856Z","shell.execute_reply.started":"2023-10-01T04:56:35.541308Z","shell.execute_reply":"2023-10-01T04:56:35.544641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exoplanet Dataset","metadata":{}},{"cell_type":"code","source":"exoTest","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:56:35.560043Z","iopub.execute_input":"2023-10-01T04:56:35.560807Z","iopub.status.idle":"2023-10-01T04:56:39.15466Z","shell.execute_reply.started":"2023-10-01T04:56:35.56077Z","shell.execute_reply":"2023-10-01T04:56:39.153081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"exoTest['FLUX.1'].value_counts().head(20).plot(kind='bar',figsize=(15,3),color='lightblue')\nplt.xticks(rotation=45)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:56:44.161041Z","iopub.execute_input":"2023-10-01T04:56:44.161471Z","iopub.status.idle":"2023-10-01T04:56:44.466764Z","shell.execute_reply.started":"2023-10-01T04:56:44.161433Z","shell.execute_reply":"2023-10-01T04:56:44.464983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Groupby by LABEL\nshape = exoTest.groupby(\"LABEL\")\n\n# Summary statistic of all countries\nshape.describe().style.background_gradient(cmap ='coolwarm').set_properties(**{'font-size': '8px'})","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:56:44.469855Z","iopub.execute_input":"2023-10-01T04:56:44.470963Z","iopub.status.idle":"2023-10-01T04:59:53.748105Z","shell.execute_reply.started":"2023-10-01T04:56:44.470906Z","shell.execute_reply":"2023-10-01T04:59:53.745909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ML\nWe have to encode the composite exoplanet dataset prior to running a machine learning model against it.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\n\ndef encode(df):\n    lb_make = LabelEncoder()\n    columns = df.columns.values.tolist()\n    df_encoded = df[columns].copy()\n\n    # categorize/encode\n    for i in columns:\n        df_encoded[i] = lb_make.fit_transform(df[i])\n\n    # encoded\n    return df_encoded\n\n# set x & y variables\nx = composite.drop(columns='discoverymethod')\ny = composite['discoverymethod'].ravel()\n\nX_train, X_test, y_train, y_test = train_test_split(x, y)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T23:41:33.670382Z","iopub.execute_input":"2023-10-01T23:41:33.670838Z","iopub.status.idle":"2023-10-01T23:41:33.693342Z","shell.execute_reply.started":"2023-10-01T23:41:33.670799Z","shell.execute_reply":"2023-10-01T23:41:33.691844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# choose target variable\n#target = input(\"Enter target variable: \")\ntarget = 'discoverymethod'#\"koi_disposition\"\n\n# quick proof of concept\na = encode(composite.copy())\n\n# find random sample\nfrom random import randrange\nidx = randrange(len(a))\n\n# print random configuration item\nb = pd.DataFrame(a.loc[idx]).T\nprint(f\"{target}:\",b.reset_index()[target][0])\n\n# store sol'n\nsolution = b.reset_index()[target][0]\n\n# print data point\nb","metadata":{"execution":{"iopub.status.busy":"2023-10-01T23:45:48.431559Z","iopub.execute_input":"2023-10-01T23:45:48.432018Z","iopub.status.idle":"2023-10-01T23:45:48.865727Z","shell.execute_reply.started":"2023-10-01T23:45:48.431984Z","shell.execute_reply":"2023-10-01T23:45:48.864424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# categorize/encode entire dataframe(a)\nc = encode(a)\nprint(\"\\nOriginal dataframe encoded.\")","metadata":{"execution":{"iopub.status.busy":"2023-10-01T23:45:57.543114Z","iopub.execute_input":"2023-10-01T23:45:57.543776Z","iopub.status.idle":"2023-10-01T23:45:57.630053Z","shell.execute_reply.started":"2023-10-01T23:45:57.543726Z","shell.execute_reply":"2023-10-01T23:45:57.628768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print encoded item\nuse_case = pd.DataFrame(c.loc[idx]).T.drop(columns=[target]) \n#c\n\n# print encoded item w/out target info\ndata = c.drop(columns=[target]) \nuse_case","metadata":{"execution":{"iopub.status.busy":"2023-10-01T23:45:59.137004Z","iopub.execute_input":"2023-10-01T23:45:59.137812Z","iopub.status.idle":"2023-10-01T23:45:59.159873Z","shell.execute_reply.started":"2023-10-01T23:45:59.13776Z","shell.execute_reply":"2023-10-01T23:45:59.158146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def X_y_sets(df, target):\n    #X = df.dropna().drop(columns=[target]).copy()\n    #y = df.dropna()[target].ravel().copy()\n    \n    # w.o dropna()\n    X = df.drop(columns=[target]).copy()\n    y = df.dropna()[target].ravel().copy()\n    \n    return train_test_split(X, y, test_size=0.33, random_state=42), X, y# save trainer\nprint(\"\\nResetting train data...\")\ntrainer = c.loc[c.index!=idx].dropna().copy()\nX, y =  trainer.drop(columns=[target]), trainer[target].ravel()\nX_train, X_test, y_train, y_test = X_y_sets(trainer, target)[0]","metadata":{"execution":{"iopub.status.busy":"2023-10-01T23:46:14.639891Z","iopub.execute_input":"2023-10-01T23:46:14.640342Z","iopub.status.idle":"2023-10-01T23:46:14.681492Z","shell.execute_reply.started":"2023-10-01T23:46:14.640304Z","shell.execute_reply":"2023-10-01T23:46:14.680239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# encoded variable re-mapping\n# specific to our current target choice\nd = encoding_remap(a, c, target)\nprint(\"\\nDecoding our encoded dataframe to correlate with the initial randomly chosen subject.\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-10-01T23:46:16.464158Z","iopub.execute_input":"2023-10-01T23:46:16.46543Z","iopub.status.idle":"2023-10-01T23:46:16.559357Z","shell.execute_reply.started":"2023-10-01T23:46:16.465376Z","shell.execute_reply":"2023-10-01T23:46:16.558055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"\\nLive prediction\\n\")\n\n# choose classifier\nclf = GradientBoostingClassifier(criterion=\"friedman_mse\", init=None, learning_rate=0.033, loss='deviance', max_depth=19, max_features=None, max_leaf_nodes=None, min_samples_leaf=60, min_samples_split=120, min_weight_fraction_leaf=0.0, n_estimators=100, random_state=42, subsample=1.0, verbose=1, warm_start=False).fit(X_train, y_train)\n#clf = RandomForestClassifier(max_depth=5, n_estimators=200, random_state=42).fit(X_train, y_train)\n#clf = ExtraTreesClassifier(n_estimators=200, random_state=42).fit(X_train, y_train)\n#clf = AdaBoostClassifier(n_estimators=200, random_state=42).fit(X_train, y_train)\n#clf = MLPClassifier(alpha=0.666, max_iter=666).fit(X_train, y_train)\n#clf = KNeighborsClassifier().fit(X_train, y_train)\n\n\nprint()\nprint(\"Test score: \",clf.score(X_test, y_test))\nprint()\nprediction = clf.predict(use_case)[0]\nprint(f\"Prediction {target}:\",prediction)\n\n\n# print decoded prediction\nprint(\"\\nPrediction Decoded\")\ne = d[d.index == prediction]\ne","metadata":{"execution":{"iopub.status.busy":"2023-10-01T23:46:20.304423Z","iopub.execute_input":"2023-10-01T23:46:20.305385Z","iopub.status.idle":"2023-10-01T23:51:34.588019Z","shell.execute_reply.started":"2023-10-01T23:46:20.305343Z","shell.execute_reply":"2023-10-01T23:51:34.586753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if solution == e.reset_index()[target][0]:\n    print(\"Machine's prediction was correct!\")\nelse:\n    print(\"Machine's prediction was incorrect :(\")","metadata":{"execution":{"iopub.status.busy":"2023-10-01T23:51:43.145363Z","iopub.execute_input":"2023-10-01T23:51:43.147124Z","iopub.status.idle":"2023-10-01T23:51:43.157209Z","shell.execute_reply.started":"2023-10-01T23:51:43.147051Z","shell.execute_reply":"2023-10-01T23:51:43.1557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pairplot Against encoded(composite) & Target Variable\nThe cell block below takes several minutes to compute.","metadata":{}},{"cell_type":"code","source":"pairplot(encode(x),y)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T23:52:10.638482Z","iopub.execute_input":"2023-10-01T23:52:10.638941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Supplementary","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n\n# classifier iteration\ndef classification_feat_importance(df_encoded):\n    \n    # iterate through each column variable as classification targets\n    for target in df_encoded.columns.values:\n        X = df_encoded.drop(columns=[target]).copy()\n        y = df_encoded[target].ravel().copy()\n\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n        \n    \n        # classifiers\n        #clf1 = GradientBoostingClassifier(criterion=\"friedman_mse\", init=None, learning_rate=0.3338, loss='deviance', max_depth=19, max_features=None, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=120, min_weight_fraction_leaf=0.0, n_estimators=500, random_state=42, subsample=1.0, verbose=1, warm_start=False).fit(X_train, y_train)\n        #clf2 = GradientBoostingClassifier(criterion=\"squared_error\", init=None, learning_rate=0.2222, loss='deviance', max_depth=19, max_features=None, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=120, min_weight_fraction_leaf=0.0, n_estimators=500, random_state=42, subsample=1.0, verbose=1, warm_start=False).fit(X_train, y_train)\n        clf3 = RandomForestClassifier(max_depth=5, n_estimators=1000, random_state=42).fit(X_train, y_train)\n        clf4 = ExtraTreesClassifier(n_estimators=200, random_state=42).fit(X_train, y_train)\n        clf5 = AdaBoostClassifier(n_estimators=8000, random_state=42).fit(X_train, y_train)\n        clf6 = MLPClassifier(alpha=1, max_iter=500).fit(X_train, y_train)\n        clf7 = KNeighborsClassifier(n_neighbors=9).fit(X_train, y_train)\n        classifiers = [\n                       #clf1, \n                       #clf2, \n                       clf3, \n                       clf4, \n                       clf5,\n                       clf6,\n                       #clf7\n                      ]\n\n        for classifier in classifiers:\n            results = []\n            results.append({\"classifier\":str(classifier).split(\"(\")[0],\"target\":target,\"test_score\":classifier.score(X_test, y_test)})\n            for i in results:\n                if target == 'verified':\n                    print(\"\\nClassifier:\",str(classifier).split(\"(\")[0],\"\\nTarget:\",target,\"\\nScore:\",classifier.score(X_test, y_test))\n        \n        test_matrix = confusion_matrix(y_test, clf.predict(X_test)) \n        results = pd.DataFrame(results)\n        \n    return results,test_matrix\n\nprint(\"To analyze which target-classifier would yield the best results: \\nUncomment (#) the code below.\")","metadata":{"execution":{"iopub.status.busy":"2023-10-01T05:00:27.763452Z","iopub.status.idle":"2023-10-01T05:00:27.763877Z","shell.execute_reply.started":"2023-10-01T05:00:27.763687Z","shell.execute_reply":"2023-10-01T05:00:27.763707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# encoding\nfrom sklearn.preprocessing import LabelEncoder\ndef encode(df):\n    lb_make = LabelEncoder()\n    columns = df.columns.values.tolist()\n    df_encoded = df[columns].copy()\n\n    # categorize/encode\n    for i in columns:\n        df_encoded[i] = lb_make.fit_transform(df[i])\n\n    # encoded\n    return df_encoded\n\n\n# encoded variable re-mapping\ndef encoding_remap(df, df_encoded, target):\n    \n    X_test = X_y_sets(df, target)[0][0]\n    \n    remap = pd.merge(df_encoded.loc[df_encoded.index.isin(X_test.index.values)][target].reset_index(),\n              df.loc[df.index.isin(X_test.index.values)][[target]].reset_index(),on=['index'])\n    \n    remap[target] = [str(remap[f'{target}_y'][i]) for i,v in remap[f'{target}_x'].items()]\n    remap['index'] = np.array([str(remap[f'{target}_x'][i]) for i,v in remap[f'{target}_x'].items()]).astype(int)\n    remap=remap[[target,'index']]\n    remap = remap.set_index('index').drop_duplicates().sort_values('index')\n    \n    return remap\n\n\n# pairplot\nimport seaborn as sns\ndef pairplot(df, target):\n    return sns.pairplot(df.sample(int(len(df/10000))),hue=target)\n    \n    \n# create X,y variables for ML\nfrom sklearn.model_selection import train_test_split\ndef X_y_sets(df, target):\n    X = df.dropna().drop(columns=[target]).copy()\n    y = df.dropna()[target].ravel().copy()\n    \n    return train_test_split(X, y, test_size=0.33, random_state=42), X, y\n\n\n# classifier iteration\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import confusion_matrix\ndef classification_feat_importance(df_encoded):\n    \n    df_encoded = df_encoded.drop(columns=['target1','target2'])\n    \n    # iterate through each column variable as classification targets\n    for target in df_encoded.columns.values:\n        X = df_encoded.dropna().drop(columns=[target]).copy()\n        y = df_encoded.dropna()[target].ravel().copy()\n\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n        \n        time.sleep(30)\n        \n        # classifiers\n        clf1 = RandomForestClassifier(max_depth=5, n_estimators=200, random_state=42).fit(X_train, y_train)\n        clf2 = AdaBoostClassifier(n_estimators=200, random_state=42).fit(X_train, y_train)\n        clf3 = ExtraTreesClassifier(n_estimators=200, random_state=42).fit(X_train, y_train)\n        clf4 = KNeighborsClassifier().fit(X_train, y_train)\n        clf5 = MLPClassifier(alpha=1, max_iter=500).fit(X_train, y_train)\n        classifiers = [\n                       clf1, \n                       clf2, \n                       clf3, \n                       clf4, \n                       clf5\n                      ]\n\n        for classifier in classifiers:\n            results = []\n            #test_matrix = confusion_matrix(y_test, clf.predict(X_test))\n            results.append({\"classifier\":str(classifier).split(\"(\")[0],\"target\":target,\"test_score\":classifier.score(X_test, y_test)})\n            print(\"Classifier:\",str(classifier).split(\"(\")[0],\"\\t\\tTarget:\",target,\"\\tScore:\",classifier.score(X_test, y_test))\n            \n    return pd.DataFrame(results)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T23:51:34.600444Z","iopub.execute_input":"2023-10-01T23:51:34.600912Z","iopub.status.idle":"2023-10-01T23:51:34.622492Z","shell.execute_reply.started":"2023-10-01T23:51:34.600865Z","shell.execute_reply":"2023-10-01T23:51:34.621358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Variable Definitions & API Documentation\nData Columns in Kepler Objects of Interest Table <br>*https://exoplanetarchive.ipac.caltech.edu/docs/API_kepcandidate_columns.html\n\n\nExoplanet Archive Application Programming Interface (API) User Guide\n<br>*https://exoplanetarchive.ipac.caltech.edu/docs/program_interfaces.html","metadata":{}},{"cell_type":"code","source":"#en fin","metadata":{"execution":{"iopub.status.busy":"2023-10-01T05:00:27.76677Z","iopub.status.idle":"2023-10-01T05:00:27.767144Z","shell.execute_reply.started":"2023-10-01T05:00:27.766947Z","shell.execute_reply":"2023-10-01T05:00:27.766966Z"},"trusted":true},"execution_count":null,"outputs":[]}]}