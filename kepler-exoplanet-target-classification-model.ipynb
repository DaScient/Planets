{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/dascient/kepler-exoplanet-classification-model?scriptVersionId=144826087\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Kepler Data Analysis","metadata":{}},{"cell_type":"code","source":"# lets begin!\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier \nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\n# for the sake of expeditious analysis\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nfrom shapely.geometry import Point\nimport geopandas as gpd\nfrom wordcloud import WordCloud, STOPWORDS\nfrom geopandas import GeoDataFrame\nimport matplotlib.colors as colors\nimport seaborn as sns\nimport random as r\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# kepler labled test & train\nexoTest = pd.read_csv('/kaggle/input/kepler-labelled-time-series-data/exoTest.csv',header=0)\nexoTrain = pd.read_csv('/kaggle/input/kepler-labelled-time-series-data/exoTrain.csv',header=0)\ncumulative = pd.read_csv('/kaggle/input/kepler-exoplanet-search-results/cumulative.csv',header=0)\ncomposite = pd.read_csv(\"/kaggle/input/httpsexoplanetarchive-ipac-caltech-edu/PSCompPars_2023.09.30_20.49.04.csv\",header=168)#,error_bad_lines=False)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-01T04:56:26.602209Z","iopub.execute_input":"2023-10-01T04:56:26.602619Z","iopub.status.idle":"2023-10-01T04:56:33.493695Z","shell.execute_reply.started":"2023-10-01T04:56:26.602585Z","shell.execute_reply":"2023-10-01T04:56:33.492392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_columns', None)\ncomposite.discoverymethod.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T05:08:13.51325Z","iopub.execute_input":"2023-10-01T05:08:13.513703Z","iopub.status.idle":"2023-10-01T05:08:13.525272Z","shell.execute_reply.started":"2023-10-01T05:08:13.513666Z","shell.execute_reply":"2023-10-01T05:08:13.523877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\n\n# graph\nfig = px.scatter_3d(composite, x='elat', y='elon', z='glat',\n              color='disc_year',\n              size = 'ra',\n              hover_name = 'hostname',\n              hover_data=['disc_locale','disc_telescope','gaia_id','hd_name','disc_facility'],              \n              opacity=0.5,\n              size_max=25\n                   )\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:56:33.701775Z","iopub.execute_input":"2023-10-01T04:56:33.702189Z","iopub.status.idle":"2023-10-01T04:56:35.276439Z","shell.execute_reply.started":"2023-10-01T04:56:33.702142Z","shell.execute_reply":"2023-10-01T04:56:35.274916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\n\n# graph\nfig = px.scatter_3d(composite, x='elat', y='elon', z='glon',\n              color='disc_year',\n              size = 'ra',\n              hover_name = 'hostname',\n              hover_data=['disc_locale','disc_telescope','gaia_id','hd_name','disc_facility'],              \n              opacity=0.5,\n              size_max=25\n                   )\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:56:35.280476Z","iopub.execute_input":"2023-10-01T04:56:35.281504Z","iopub.status.idle":"2023-10-01T04:56:35.539104Z","shell.execute_reply.started":"2023-10-01T04:56:35.281444Z","shell.execute_reply":"2023-10-01T04:56:35.538092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# datasets\n#exoTest.describe()#.style.background_gradient(cmap ='coolwarm').set_properties(**{'font-size': '8px'})\n#exoTrain.describe()#.style.background_gradient(cmap ='coolwarm').set_properties(**{'font-size': '8px'})\n#cumulative.describe()#.style.background_gradient(cmap ='coolwarm').set_properties(**{'font-size': '8px'})","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:56:35.540508Z","iopub.execute_input":"2023-10-01T04:56:35.541346Z","iopub.status.idle":"2023-10-01T04:56:35.545856Z","shell.execute_reply.started":"2023-10-01T04:56:35.541308Z","shell.execute_reply":"2023-10-01T04:56:35.544641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# kepler target\n# pairplot\n#target = 'kepler_name'#'koi_disposition'\n#sns.pairplot(df_encoded.sample(int(len(df_encoded/1000))),hue=target)\n#sns.pairplot(df_encoded.sample(10),hue=target)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:56:35.547425Z","iopub.execute_input":"2023-10-01T04:56:35.547989Z","iopub.status.idle":"2023-10-01T04:56:35.558471Z","shell.execute_reply.started":"2023-10-01T04:56:35.547952Z","shell.execute_reply":"2023-10-01T04:56:35.557166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exoplanet Dataset","metadata":{}},{"cell_type":"code","source":"exoTest","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:56:35.560043Z","iopub.execute_input":"2023-10-01T04:56:35.560807Z","iopub.status.idle":"2023-10-01T04:56:39.15466Z","shell.execute_reply.started":"2023-10-01T04:56:35.56077Z","shell.execute_reply":"2023-10-01T04:56:39.153081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"exoTest['FLUX.1'].value_counts().head(20).plot(kind='bar',figsize=(15,3),color='lightblue')\nplt.xticks(rotation=45)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:56:44.161041Z","iopub.execute_input":"2023-10-01T04:56:44.161471Z","iopub.status.idle":"2023-10-01T04:56:44.466764Z","shell.execute_reply.started":"2023-10-01T04:56:44.161433Z","shell.execute_reply":"2023-10-01T04:56:44.464983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Groupby by LABEL\nshape = exoTest.groupby(\"LABEL\")\n\n# Summary statistic of all countries\nshape.describe().style.background_gradient(cmap ='coolwarm').set_properties(**{'font-size': '8px'})","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:56:44.469855Z","iopub.execute_input":"2023-10-01T04:56:44.470963Z","iopub.status.idle":"2023-10-01T04:59:53.748105Z","shell.execute_reply.started":"2023-10-01T04:56:44.470906Z","shell.execute_reply":"2023-10-01T04:59:53.745909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ML","metadata":{}},{"cell_type":"code","source":"# Set up Xy Test & Train sets\nX_train, X_test, y_train, y_test = exoTrain.drop(columns='LABEL'), exoTest.drop(columns='LABEL'), exoTrain.LABEL.values, exoTest.LABEL.values","metadata":{"execution":{"iopub.status.busy":"2023-10-01T05:13:43.219416Z","iopub.execute_input":"2023-10-01T05:13:43.219894Z","iopub.status.idle":"2023-10-01T05:13:43.296542Z","shell.execute_reply.started":"2023-10-01T05:13:43.219853Z","shell.execute_reply":"2023-10-01T05:13:43.294818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = 'discoverymethod'\n\n# classifier\n#clf = RandomForestClassifier(max_depth=5, n_estimators=200, random_state=42).fit(X_train, y_train)\n#clf = AdaBoostClassifier(n_estimators=200, random_state=42).fit(X_train, y_train)\nclf = ExtraTreesClassifier(n_estimators=200, random_state=42).fit(X_train, y_train)\n#clf = KNeighborsClassifier().fit(X_train, y_train)\n#clf = MLPClassifier(alpha=1, max_iter=500).fit(X_train, y_train)\n\n# results\ntrain_predications = clf.predict(X_train)\ntrain_score = clf.score(X_train, y_train)\npredictions = clf.predict(X_test)\nscore = clf.score(X_test, y_test)\ntrain_matrix = confusion_matrix(y_train, train_predications)\ntest_matrix = confusion_matrix(y_test, predictions)\nprint(\"Target:\",target)\nprint(\"TRAIN SCORE:\",train_score)\nprint(\"TEST SCORE:\",score)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T05:13:44.917767Z","iopub.execute_input":"2023-10-01T05:13:44.918243Z","iopub.status.idle":"2023-10-01T05:13:51.514503Z","shell.execute_reply.started":"2023-10-01T05:13:44.918203Z","shell.execute_reply":"2023-10-01T05:13:51.512743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"matrix = pd.DataFrame(test_matrix)\n\nmatrix.style.background_gradient(cmap ='Spectral')\\\n        .set_properties(**{'font-size': '15px'})","metadata":{"execution":{"iopub.status.busy":"2023-10-01T05:13:54.85723Z","iopub.execute_input":"2023-10-01T05:13:54.857637Z","iopub.status.idle":"2023-10-01T05:13:54.880942Z","shell.execute_reply.started":"2023-10-01T05:13:54.857602Z","shell.execute_reply":"2023-10-01T05:13:54.879857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# noise\npd.DataFrame(y_test-clf.predict(X_test),columns=['Miscalculations']).plot(figsize=(20,5),c='purple')","metadata":{"execution":{"iopub.status.busy":"2023-10-01T05:00:00.544186Z","iopub.execute_input":"2023-10-01T05:00:00.545209Z","iopub.status.idle":"2023-10-01T05:00:00.892693Z","shell.execute_reply.started":"2023-10-01T05:00:00.545161Z","shell.execute_reply":"2023-10-01T05:00:00.891356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n\n# classifier iteration\ndef classification_feat_importance(df_encoded):\n    \n    # iterate through each column variable as classification targets\n    for target in df_encoded.columns.values:\n        X = df_encoded.drop(columns=[target]).copy()\n        y = df_encoded[target].ravel().copy()\n\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n        \n        time.sleep(10)\n\n        # classifiers\n        #clf1 = GradientBoostingClassifier(criterion=\"friedman_mse\", init=None, learning_rate=0.3338, loss='deviance', max_depth=19, max_features=None, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=120, min_weight_fraction_leaf=0.0, n_estimators=500, random_state=42, subsample=1.0, verbose=1, warm_start=False).fit(X_train, y_train)\n        #clf2 = GradientBoostingClassifier(criterion=\"squared_error\", init=None, learning_rate=0.2222, loss='deviance', max_depth=19, max_features=None, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=120, min_weight_fraction_leaf=0.0, n_estimators=500, random_state=42, subsample=1.0, verbose=1, warm_start=False).fit(X_train, y_train)\n        clf3 = RandomForestClassifier(max_depth=5, n_estimators=1000, random_state=42).fit(X_train, y_train)\n        clf4 = ExtraTreesClassifier(n_estimators=200, random_state=42).fit(X_train, y_train)\n        clf5 = AdaBoostClassifier(n_estimators=8000, random_state=42).fit(X_train, y_train)\n        clf6 = MLPClassifier(alpha=1, max_iter=500).fit(X_train, y_train)\n        clf7 = KNeighborsClassifier(n_neighbors=9).fit(X_train, y_train)\n        classifiers = [\n                       #clf1, \n                       #clf2, \n                       clf3, \n                       clf4, \n                       clf5,\n                       clf6,\n                       #clf7\n                      ]\n\n        for classifier in classifiers:\n            results = []\n            results.append({\"classifier\":str(classifier).split(\"(\")[0],\"target\":target,\"test_score\":classifier.score(X_test, y_test)})\n            for i in results:\n                if target == 'verified':\n                    print(\"\\nClassifier:\",str(classifier).split(\"(\")[0],\"\\nTarget:\",target,\"\\nScore:\",classifier.score(X_test, y_test))\n        \n        test_matrix = confusion_matrix(y_test, clf.predict(X_test)) \n        results = pd.DataFrame(results)\n        \n    return results,test_matrix\n\nprint(\"To analyze which target-classifier would yield the best results: \\nUncomment (#) the code below.\")","metadata":{"execution":{"iopub.status.busy":"2023-10-01T05:00:00.894265Z","iopub.execute_input":"2023-10-01T05:00:00.894641Z","iopub.status.idle":"2023-10-01T05:00:00.908222Z","shell.execute_reply.started":"2023-10-01T05:00:00.894557Z","shell.execute_reply":"2023-10-01T05:00:00.906817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classification_feat_importance(exoTest.head())","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# choose target variable\n#target = input(\"Enter target variable: \")\ntarget = 'LABEL'#\"koi_disposition\"\n\n# quick proof of concept\na = exoTest.copy()\n\n# find random sample\nfrom random import randrange\nidx = randrange(len(a))\n\n# print random configuration item\nb = pd.DataFrame(a.loc[idx]).T\nprint(f\"{target}:\",b.reset_index()[target][0])\n\n# store sol'n\nsolution = b.reset_index()[target][0]\n\n# print data point\nb","metadata":{"execution":{"iopub.status.busy":"2023-10-01T05:18:23.865651Z","iopub.execute_input":"2023-10-01T05:18:23.866029Z","iopub.status.idle":"2023-10-01T05:18:25.670947Z","shell.execute_reply.started":"2023-10-01T05:18:23.865996Z","shell.execute_reply":"2023-10-01T05:18:25.669683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# categorize/encode entire dataframe(a)\ndef encode(df):\n    lb_make = LabelEncoder()\n    columns = df.columns.values.tolist()\n    df_encoded = df[columns].copy()\n\n    # categorize/encode\n    for i in columns:\n        df_encoded[i] = lb_make.fit_transform(df[i])\n\n    # encoded\n    return df_encoded\n\nc = encode(a)\nprint(\"\\nOriginal dataframe encoded.\")","metadata":{"execution":{"iopub.status.busy":"2023-10-01T05:18:25.672714Z","iopub.execute_input":"2023-10-01T05:18:25.6737Z","iopub.status.idle":"2023-10-01T05:18:31.361435Z","shell.execute_reply.started":"2023-10-01T05:18:25.673662Z","shell.execute_reply":"2023-10-01T05:18:31.360409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print encoded item\nuse_case = pd.DataFrame(c.loc[idx]).T.drop(columns=[target]) \n#c\n\n# print encoded item w/out target info\ndata = c.drop(columns=[target]) \nuse_case","metadata":{"execution":{"iopub.status.busy":"2023-10-01T05:18:31.362524Z","iopub.execute_input":"2023-10-01T05:18:31.363539Z","iopub.status.idle":"2023-10-01T05:18:32.179702Z","shell.execute_reply.started":"2023-10-01T05:18:31.363486Z","shell.execute_reply":"2023-10-01T05:18:32.178634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def X_y_sets(df, target):\n    #X = df.dropna().drop(columns=[target]).copy()\n    #y = df.dropna()[target].ravel().copy()\n    \n    # w.o dropna()\n    X = df.drop(columns=[target]).copy()\n    y = df.dropna()[target].ravel().copy()\n    \n    return train_test_split(X, y, test_size=0.33, random_state=42), X, y# save trainer\nprint(\"\\nResetting train data...\")\ntrainer = c.loc[c.index!=idx].dropna().copy()\nX, y =  trainer.drop(columns=[target]), trainer[target].ravel()\nX_train, X_test, y_train, y_test = X_y_sets(trainer, target)[0]","metadata":{"execution":{"iopub.status.busy":"2023-10-01T05:18:32.181775Z","iopub.execute_input":"2023-10-01T05:18:32.182737Z","iopub.status.idle":"2023-10-01T05:18:32.248411Z","shell.execute_reply.started":"2023-10-01T05:18:32.182698Z","shell.execute_reply":"2023-10-01T05:18:32.246756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# encoded variable re-mapping\n# specific to our current target choice\nd = encoding_remap(a, c, target)\nprint(\"\\nDecoding our encoded dataframe to correlate with the initial randomly chosen subject.\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-10-01T05:18:32.250564Z","iopub.execute_input":"2023-10-01T05:18:32.250915Z","iopub.status.idle":"2023-10-01T05:18:32.316283Z","shell.execute_reply.started":"2023-10-01T05:18:32.250883Z","shell.execute_reply":"2023-10-01T05:18:32.314941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"\\nLive prediction\\n\")\n\n# choose classifier\nclf = GradientBoostingClassifier(criterion=\"friedman_mse\", init=None, learning_rate=0.033, loss='deviance', max_depth=19, max_features=None, max_leaf_nodes=None, min_samples_leaf=60, min_samples_split=120, min_weight_fraction_leaf=0.0, n_estimators=100, random_state=42, subsample=1.0, verbose=1, warm_start=False).fit(X_train, y_train)\n#clf = RandomForestClassifier(max_depth=5, n_estimators=200, random_state=42).fit(X_train, y_train)\n#clf = ExtraTreesClassifier(n_estimators=200, random_state=42).fit(X_train, y_train)\n#clf = AdaBoostClassifier(n_estimators=200, random_state=42).fit(X_train, y_train)\n#clf = MLPClassifier(alpha=0.666, max_iter=666).fit(X_train, y_train)\n#clf = KNeighborsClassifier().fit(X_train, y_train)\n\n\nprint()\nprint(\"Test score: \",clf.score(X_test, y_test))\nprint()\nprediction = clf.predict(use_case)[0]\nprint(f\"Prediction {target}:\",prediction)\n\n\n# print decoded prediction\nprint(\"\\nPrediction Decoded\")\ne = d[d.index == prediction]\ne","metadata":{"execution":{"iopub.status.busy":"2023-10-01T05:19:58.80133Z","iopub.execute_input":"2023-10-01T05:19:58.80175Z","iopub.status.idle":"2023-10-01T05:20:30.838756Z","shell.execute_reply.started":"2023-10-01T05:19:58.801712Z","shell.execute_reply":"2023-10-01T05:20:30.837291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if solution == e.reset_index()[target][0]:\n    print(\"Machine's prediction was correct!\")\nelse:\n    print(\"Machine's prediction was incorrect :(\")","metadata":{"execution":{"iopub.status.busy":"2023-10-01T05:20:36.777815Z","iopub.execute_input":"2023-10-01T05:20:36.778216Z","iopub.status.idle":"2023-10-01T05:20:36.786337Z","shell.execute_reply.started":"2023-10-01T05:20:36.778181Z","shell.execute_reply":"2023-10-01T05:20:36.784498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- I believe the machine's inability to predict correctly is due to a class-oriented issue in the cell above in which I define the X_y_sets function. \n- I might be seeking @jasonifier as an SME to address this issue by uniquely debugging my code. Otherwise, feel free to comment as to why setting the X variable  [(df.dropna().drop(columns=[target]).copy()] returns an empty set - Despite having X_test.info() identifies each variable to be non-null's?\n- I'll be attending to fix this as quickly as I can. ","metadata":{}},{"cell_type":"markdown","source":"# Supplementary","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n\n# classifier iteration\ndef classification_feat_importance(df_encoded):\n    \n    # iterate through each column variable as classification targets\n    for target in df_encoded.columns.values:\n        X = df_encoded.drop(columns=[target]).copy()\n        y = df_encoded[target].ravel().copy()\n\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n        \n    \n        # classifiers\n        #clf1 = GradientBoostingClassifier(criterion=\"friedman_mse\", init=None, learning_rate=0.3338, loss='deviance', max_depth=19, max_features=None, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=120, min_weight_fraction_leaf=0.0, n_estimators=500, random_state=42, subsample=1.0, verbose=1, warm_start=False).fit(X_train, y_train)\n        #clf2 = GradientBoostingClassifier(criterion=\"squared_error\", init=None, learning_rate=0.2222, loss='deviance', max_depth=19, max_features=None, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=120, min_weight_fraction_leaf=0.0, n_estimators=500, random_state=42, subsample=1.0, verbose=1, warm_start=False).fit(X_train, y_train)\n        clf3 = RandomForestClassifier(max_depth=5, n_estimators=1000, random_state=42).fit(X_train, y_train)\n        clf4 = ExtraTreesClassifier(n_estimators=200, random_state=42).fit(X_train, y_train)\n        clf5 = AdaBoostClassifier(n_estimators=8000, random_state=42).fit(X_train, y_train)\n        clf6 = MLPClassifier(alpha=1, max_iter=500).fit(X_train, y_train)\n        clf7 = KNeighborsClassifier(n_neighbors=9).fit(X_train, y_train)\n        classifiers = [\n                       #clf1, \n                       #clf2, \n                       clf3, \n                       clf4, \n                       clf5,\n                       clf6,\n                       #clf7\n                      ]\n\n        for classifier in classifiers:\n            results = []\n            results.append({\"classifier\":str(classifier).split(\"(\")[0],\"target\":target,\"test_score\":classifier.score(X_test, y_test)})\n            for i in results:\n                if target == 'verified':\n                    print(\"\\nClassifier:\",str(classifier).split(\"(\")[0],\"\\nTarget:\",target,\"\\nScore:\",classifier.score(X_test, y_test))\n        \n        test_matrix = confusion_matrix(y_test, clf.predict(X_test)) \n        results = pd.DataFrame(results)\n        \n    return results,test_matrix\n\nprint(\"To analyze which target-classifier would yield the best results: \\nUncomment (#) the code below.\")","metadata":{"execution":{"iopub.status.busy":"2023-10-01T05:00:27.763452Z","iopub.status.idle":"2023-10-01T05:00:27.763877Z","shell.execute_reply.started":"2023-10-01T05:00:27.763687Z","shell.execute_reply":"2023-10-01T05:00:27.763707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# encoding\nfrom sklearn.preprocessing import LabelEncoder\ndef encode(df):\n    lb_make = LabelEncoder()\n    columns = df.columns.values.tolist()\n    df_encoded = df[columns].copy()\n\n    # categorize/encode\n    for i in columns:\n        df_encoded[i] = lb_make.fit_transform(df[i])\n\n    # encoded\n    return df_encoded\n\n\n# encoded variable re-mapping\ndef encoding_remap(df, df_encoded, target):\n    \n    X_test = X_y_sets(df, target)[0][0]\n    \n    remap = pd.merge(df_encoded.loc[df_encoded.index.isin(X_test.index.values)][target].reset_index(),\n              df.loc[df.index.isin(X_test.index.values)][[target]].reset_index(),on=['index'])\n    \n    remap[target] = [str(remap[f'{target}_y'][i]) for i,v in remap[f'{target}_x'].items()]\n    remap['index'] = np.array([str(remap[f'{target}_x'][i]) for i,v in remap[f'{target}_x'].items()]).astype(int)\n    remap=remap[[target,'index']]\n    remap = remap.set_index('index').drop_duplicates().sort_values('index')\n    \n    return remap\n\n\n# pairplot\nimport seaborn as sns\ndef pairplot(df, target):\n    return sns.pairplot(df.sample(int(len(df/10000))),hue=target)\n    \n    \n# create X,y variables for ML\nfrom sklearn.model_selection import train_test_split\ndef X_y_sets(df, target):\n    X = df.dropna().drop(columns=[target]).copy()\n    y = df.dropna()[target].ravel().copy()\n    \n    return train_test_split(X, y, test_size=0.33, random_state=42), X, y\n\n\n# classifier iteration\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import confusion_matrix\ndef classification_feat_importance(df_encoded):\n    \n    df_encoded = df_encoded.drop(columns=['target1','target2'])\n    \n    # iterate through each column variable as classification targets\n    for target in df_encoded.columns.values:\n        X = df_encoded.dropna().drop(columns=[target]).copy()\n        y = df_encoded.dropna()[target].ravel().copy()\n\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n        \n        time.sleep(30)\n        \n        # classifiers\n        clf1 = RandomForestClassifier(max_depth=5, n_estimators=200, random_state=42).fit(X_train, y_train)\n        clf2 = AdaBoostClassifier(n_estimators=200, random_state=42).fit(X_train, y_train)\n        clf3 = ExtraTreesClassifier(n_estimators=200, random_state=42).fit(X_train, y_train)\n        clf4 = KNeighborsClassifier().fit(X_train, y_train)\n        clf5 = MLPClassifier(alpha=1, max_iter=500).fit(X_train, y_train)\n        classifiers = [\n                       clf1, \n                       clf2, \n                       clf3, \n                       clf4, \n                       clf5\n                      ]\n\n        for classifier in classifiers:\n            results = []\n            #test_matrix = confusion_matrix(y_test, clf.predict(X_test))\n            results.append({\"classifier\":str(classifier).split(\"(\")[0],\"target\":target,\"test_score\":classifier.score(X_test, y_test)})\n            print(\"Classifier:\",str(classifier).split(\"(\")[0],\"\\t\\tTarget:\",target,\"\\tScore:\",classifier.score(X_test, y_test))\n            \n    return pd.DataFrame(results)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T05:16:09.525595Z","iopub.execute_input":"2023-10-01T05:16:09.525968Z","iopub.status.idle":"2023-10-01T05:16:09.552814Z","shell.execute_reply.started":"2023-10-01T05:16:09.525937Z","shell.execute_reply":"2023-10-01T05:16:09.551752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Variable Definitions & API Documentation\nData Columns in Kepler Objects of Interest Table <br>*https://exoplanetarchive.ipac.caltech.edu/docs/API_kepcandidate_columns.html\n\n\nExoplanet Archive Application Programming Interface (API) User Guide\n<br>*https://exoplanetarchive.ipac.caltech.edu/docs/program_interfaces.html","metadata":{}},{"cell_type":"code","source":"#en fin","metadata":{"execution":{"iopub.status.busy":"2023-10-01T05:00:27.76677Z","iopub.status.idle":"2023-10-01T05:00:27.767144Z","shell.execute_reply.started":"2023-10-01T05:00:27.766947Z","shell.execute_reply":"2023-10-01T05:00:27.766966Z"},"trusted":true},"execution_count":null,"outputs":[]}]}