{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/dascient/kepler-exoplanet-classification-model?scriptVersionId=144821974\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Kepler Data Analysis","metadata":{}},{"cell_type":"code","source":"# lets begin!\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\n# for the sake of expeditious analysis\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nfrom shapely.geometry import Point\nimport geopandas as gpd\nfrom wordcloud import WordCloud, STOPWORDS\nfrom geopandas import GeoDataFrame\nimport matplotlib.colors as colors\nimport seaborn as sns\nimport random as r\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# kepler labled test & train\nexoTest = pd.read_csv('/kaggle/input/kepler-labelled-time-series-data/exoTest.csv',header=0)\nexoTrain = pd.read_csv('/kaggle/input/kepler-labelled-time-series-data/exoTrain.csv',header=0)\ncumulative = pd.read_csv('/kaggle/input/kepler-exoplanet-search-results/cumulative.csv',header=0)\ncomposite = pd.read_csv(\"/kaggle/input/httpsexoplanetarchive-ipac-caltech-edu/PSCompPars_2023.09.30_20.49.04.csv\",header=168)#,error_bad_lines=False)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-01T04:01:57.884831Z","iopub.execute_input":"2023-10-01T04:01:57.885401Z","iopub.status.idle":"2023-10-01T04:02:03.290217Z","shell.execute_reply.started":"2023-10-01T04:01:57.885362Z","shell.execute_reply":"2023-10-01T04:02:03.288488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_columns', None)\ncomposite","metadata":{"execution":{"iopub.status.busy":"2023-10-01T03:55:18.496037Z","iopub.execute_input":"2023-10-01T03:55:18.496432Z","iopub.status.idle":"2023-10-01T03:55:18.688988Z","shell.execute_reply.started":"2023-10-01T03:55:18.496399Z","shell.execute_reply":"2023-10-01T03:55:18.687585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\n\n# graph\nfig = px.scatter_3d(composite, x='elat', y='elon', z='glat',\n              color='disc_year',\n              size = 'ra',\n              hover_name = 'hostname',\n              hover_data=['disc_locale','disc_telescope','gaia_id','hd_name','disc_facility'],              \n              opacity=0.5,\n              size_max=25\n                   )\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:00:37.611598Z","iopub.execute_input":"2023-10-01T04:00:37.611981Z","iopub.status.idle":"2023-10-01T04:00:37.881569Z","shell.execute_reply.started":"2023-10-01T04:00:37.611947Z","shell.execute_reply":"2023-10-01T04:00:37.880245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\n\n# graph\nfig = px.scatter_3d(composite, x='elat', y='elon', z='glon',\n              color='disc_year',\n              size = 'ra',\n              hover_name = 'hostname',\n              hover_data=['disc_locale','disc_telescope','gaia_id','hd_name','disc_facility'],              \n              opacity=0.5,\n              size_max=25\n                   )\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:00:58.891248Z","iopub.execute_input":"2023-10-01T04:00:58.891717Z","iopub.status.idle":"2023-10-01T04:00:59.427704Z","shell.execute_reply.started":"2023-10-01T04:00:58.891674Z","shell.execute_reply":"2023-10-01T04:00:59.426621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# datasets\n#exoTest.describe()#.style.background_gradient(cmap ='coolwarm').set_properties(**{'font-size': '8px'})\n#exoTrain.describe()#.style.background_gradient(cmap ='coolwarm').set_properties(**{'font-size': '8px'})\n#cumulative.describe()#.style.background_gradient(cmap ='coolwarm').set_properties(**{'font-size': '8px'})","metadata":{"execution":{"iopub.status.busy":"2023-04-30T07:39:05.429886Z","iopub.execute_input":"2023-04-30T07:39:05.430368Z","iopub.status.idle":"2023-04-30T07:39:05.435136Z","shell.execute_reply.started":"2023-04-30T07:39:05.430341Z","shell.execute_reply":"2023-04-30T07:39:05.434107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# kepler target\n# pairplot\n#target = 'kepler_name'#'koi_disposition'\n#sns.pairplot(df_encoded.sample(int(len(df_encoded/1000))),hue=target)\n#sns.pairplot(df_encoded.sample(10),hue=target)","metadata":{"execution":{"iopub.status.busy":"2023-04-30T07:39:05.436517Z","iopub.execute_input":"2023-04-30T07:39:05.437107Z","iopub.status.idle":"2023-04-30T07:39:05.449245Z","shell.execute_reply.started":"2023-04-30T07:39:05.437062Z","shell.execute_reply":"2023-04-30T07:39:05.447845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"exoTest","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:02:17.029251Z","iopub.execute_input":"2023-10-01T04:02:17.029674Z","iopub.status.idle":"2023-10-01T04:02:20.75391Z","shell.execute_reply.started":"2023-10-01T04:02:17.029635Z","shell.execute_reply":"2023-10-01T04:02:20.752669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\n\nplot = exoTest[exoTest['FLUX.1']>0]\nfig = px.scatter_3d(plot, x='FLUX.2', y='FLUX.3', z='FLUX.4',\n              color='LABEL',\n              size = 'FLUX.1',\n              #symbol = 'state',\n              opacity=0.7,\n              size_max=13,                    \n                   )\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T04:05:47.853001Z","iopub.execute_input":"2023-10-01T04:05:47.853385Z","iopub.status.idle":"2023-10-01T04:05:47.918347Z","shell.execute_reply.started":"2023-10-01T04:05:47.853355Z","shell.execute_reply":"2023-10-01T04:05:47.917085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\nplt.rcParams[\"xtick.labelsize\"] = 5\n\n# plot a sample of 100 observations that lasted under 60 minutes\n# need to get a smaller sample of city-set, the x-axis is way too muddled.\nsns.catplot(data=exoTest.sample(100), x=\"FLUX.11\", \n            y=\"FLUX.12\", \n            hue=\"LABEL\", \n            kind=\"swarm\", \n            height=10, \n            aspect=2, \n            size = 5)\nplt.xticks(rotation=45)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-30T08:00:08.76797Z","iopub.execute_input":"2023-04-30T08:00:08.768353Z","iopub.status.idle":"2023-04-30T08:00:12.555578Z","shell.execute_reply.started":"2023-04-30T08:00:08.76832Z","shell.execute_reply":"2023-04-30T08:00:12.554369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"exoTest['FLUX.1'].value_counts().head(20).plot(kind='bar',figsize=(15,3),color='lightblue')\nplt.xticks(rotation=45)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-30T08:01:05.578502Z","iopub.execute_input":"2023-04-30T08:01:05.578918Z","iopub.status.idle":"2023-04-30T08:01:05.800271Z","shell.execute_reply.started":"2023-04-30T08:01:05.578881Z","shell.execute_reply":"2023-04-30T08:01:05.799469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Groupby by LABEL\nshape = exoTest.groupby(\"LABEL\")\n\n# Summary statistic of all countries\nshape.describe().style.background_gradient(cmap ='coolwarm').set_properties(**{'font-size': '8px'})","metadata":{"execution":{"iopub.status.busy":"2023-04-30T08:02:39.768138Z","iopub.execute_input":"2023-04-30T08:02:39.768491Z","iopub.status.idle":"2023-04-30T08:05:21.758988Z","shell.execute_reply.started":"2023-04-30T08:02:39.768461Z","shell.execute_reply":"2023-04-30T08:05:21.757886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ML","metadata":{}},{"cell_type":"code","source":"# Set up Xy Test & Train sets\nX_train, X_test, y_train, y_test = exoTrain.drop(columns='LABEL'), exoTest.drop(columns='LABEL'), exoTrain.LABEL.values, exoTest.LABEL.values","metadata":{"execution":{"iopub.status.busy":"2023-04-30T06:52:34.789361Z","iopub.execute_input":"2023-04-30T06:52:34.789911Z","iopub.status.idle":"2023-04-30T06:52:34.843315Z","shell.execute_reply.started":"2023-04-30T06:52:34.789863Z","shell.execute_reply":"2023-04-30T06:52:34.841443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = 'LABEL'\n\n# classifier\n#clf = RandomForestClassifier(max_depth=5, n_estimators=200, random_state=42).fit(X_train, y_train)\n#clf = AdaBoostClassifier(n_estimators=200, random_state=42).fit(X_train, y_train)\nclf = ExtraTreesClassifier(n_estimators=200, random_state=42).fit(X_train, y_train)\n#clf = KNeighborsClassifier().fit(X_train, y_train)\n#clf = MLPClassifier(alpha=1, max_iter=500).fit(X_train, y_train)\n\n# results\ntrain_predications = clf.predict(X_train)\ntrain_score = clf.score(X_train, y_train)\npredictions = clf.predict(X_test)\nscore = clf.score(X_test, y_test)\ntrain_matrix = confusion_matrix(y_train, train_predications)\ntest_matrix = confusion_matrix(y_test, predictions)\nprint(\"Target:\",target)\nprint(\"TRAIN SCORE:\",train_score)\nprint(\"TEST SCORE:\",score)","metadata":{"execution":{"iopub.status.busy":"2023-04-29T07:14:15.784207Z","iopub.execute_input":"2023-04-29T07:14:15.784688Z","iopub.status.idle":"2023-04-29T07:14:22.523353Z","shell.execute_reply.started":"2023-04-29T07:14:15.784638Z","shell.execute_reply":"2023-04-29T07:14:22.522043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"matrix = pd.DataFrame(test_matrix)\n\nmatrix.style.background_gradient(cmap ='Spectral')\\\n        .set_properties(**{'font-size': '15px'})","metadata":{"execution":{"iopub.status.busy":"2023-03-23T01:44:32.657701Z","iopub.execute_input":"2023-03-23T01:44:32.658084Z","iopub.status.idle":"2023-03-23T01:45:26.53815Z","shell.execute_reply.started":"2023-03-23T01:44:32.658054Z","shell.execute_reply":"2023-03-23T01:45:26.535697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# noise\npd.DataFrame(y_test-clf.predict(X_test),columns=['Miscalculations']).plot(figsize=(20,5),c='purple')","metadata":{"execution":{"iopub.status.busy":"2023-04-29T07:14:36.094179Z","iopub.execute_input":"2023-04-29T07:14:36.095343Z","iopub.status.idle":"2023-04-29T07:14:36.575937Z","shell.execute_reply.started":"2023-04-29T07:14:36.095284Z","shell.execute_reply":"2023-04-29T07:14:36.574602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n\n# classifier iteration\ndef classification_feat_importance(df_encoded):\n    \n    # iterate through each column variable as classification targets\n    for target in df_encoded.columns.values:\n        X = df_encoded.drop(columns=[target]).copy()\n        y = df_encoded[target].ravel().copy()\n\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n        \n        time.sleep(10)\n\n        # classifiers\n        #clf1 = GradientBoostingClassifier(criterion=\"friedman_mse\", init=None, learning_rate=0.3338, loss='deviance', max_depth=19, max_features=None, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=120, min_weight_fraction_leaf=0.0, n_estimators=500, random_state=42, subsample=1.0, verbose=1, warm_start=False).fit(X_train, y_train)\n        #clf2 = GradientBoostingClassifier(criterion=\"squared_error\", init=None, learning_rate=0.2222, loss='deviance', max_depth=19, max_features=None, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=120, min_weight_fraction_leaf=0.0, n_estimators=500, random_state=42, subsample=1.0, verbose=1, warm_start=False).fit(X_train, y_train)\n        clf3 = RandomForestClassifier(max_depth=5, n_estimators=1000, random_state=42).fit(X_train, y_train)\n        clf4 = ExtraTreesClassifier(n_estimators=200, random_state=42).fit(X_train, y_train)\n        clf5 = AdaBoostClassifier(n_estimators=8000, random_state=42).fit(X_train, y_train)\n        clf6 = MLPClassifier(alpha=1, max_iter=500).fit(X_train, y_train)\n        clf7 = KNeighborsClassifier(n_neighbors=9).fit(X_train, y_train)\n        classifiers = [\n                       #clf1, \n                       #clf2, \n                       clf3, \n                       clf4, \n                       clf5,\n                       clf6,\n                       #clf7\n                      ]\n\n        for classifier in classifiers:\n            results = []\n            results.append({\"classifier\":str(classifier).split(\"(\")[0],\"target\":target,\"test_score\":classifier.score(X_test, y_test)})\n            for i in results:\n                if target == 'verified':\n                    print(\"\\nClassifier:\",str(classifier).split(\"(\")[0],\"\\nTarget:\",target,\"\\nScore:\",classifier.score(X_test, y_test))\n        \n        test_matrix = confusion_matrix(y_test, clf.predict(X_test)) \n        results = pd.DataFrame(results)\n        \n    return results,test_matrix\n\nprint(\"To analyze which target-classifier would yield the best results: \\nUncomment (#) the code below.\")","metadata":{"execution":{"iopub.status.busy":"2023-04-30T08:05:46.89442Z","iopub.execute_input":"2023-04-30T08:05:46.89554Z","iopub.status.idle":"2023-04-30T08:05:46.908948Z","shell.execute_reply.started":"2023-04-30T08:05:46.895493Z","shell.execute_reply":"2023-04-30T08:05:46.907651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classification_feat_importance(exoTest.head())","metadata":{"execution":{"iopub.status.busy":"2023-04-30T08:06:04.72531Z","iopub.execute_input":"2023-04-30T08:06:04.72571Z","iopub.status.idle":"2023-04-30T08:06:18.920551Z","shell.execute_reply.started":"2023-04-30T08:06:04.72568Z","shell.execute_reply":"2023-04-30T08:06:18.919002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# choose target variable\n#target = input(\"Enter target variable: \")\ntarget = 'kepler_name'#\"koi_disposition\"\n\n# quick proof of concept\na = df.copy()\n\n# find random sample\nfrom random import randrange\nidx = randrange(len(a))\n\n# print random configuration item\nb = pd.DataFrame(a.loc[idx]).T\nprint(f\"{target}:\",b.reset_index()[target][0])\n\n# store sol'n\nsolution = b.reset_index()[target][0]\n\n# print data point\nb","metadata":{"execution":{"iopub.status.busy":"2023-03-23T01:45:30.776631Z","iopub.execute_input":"2023-03-23T01:45:30.778081Z","iopub.status.idle":"2023-03-23T01:45:30.815308Z","shell.execute_reply.started":"2023-03-23T01:45:30.778028Z","shell.execute_reply":"2023-03-23T01:45:30.813609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# categorize/encode entire dataframe(a)\ndef encode(df):\n    lb_make = LabelEncoder()\n    columns = df.columns.values.tolist()\n    df_encoded = df[columns].copy()\n\n    # categorize/encode\n    for i in columns:\n        df_encoded[i] = lb_make.fit_transform(df[i])\n\n    # encoded\n    return df_encoded\n\nc = encode(a)\nprint(\"\\nOriginal dataframe encoded.\")","metadata":{"execution":{"iopub.status.busy":"2023-03-23T01:45:30.816696Z","iopub.execute_input":"2023-03-23T01:45:30.817006Z","iopub.status.idle":"2023-03-23T01:45:30.915206Z","shell.execute_reply.started":"2023-03-23T01:45:30.816978Z","shell.execute_reply":"2023-03-23T01:45:30.91385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print encoded item\nuse_case = pd.DataFrame(c.loc[idx]).T.drop(columns=[target]) \n#c\n\n# print encoded item w/out target info\ndata = c.drop(columns=[target]) \nuse_case","metadata":{"execution":{"iopub.status.busy":"2023-03-23T01:45:30.917802Z","iopub.execute_input":"2023-03-23T01:45:30.918296Z","iopub.status.idle":"2023-03-23T01:45:30.942116Z","shell.execute_reply.started":"2023-03-23T01:45:30.918255Z","shell.execute_reply":"2023-03-23T01:45:30.940526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def X_y_sets(df, target):\n    #X = df.dropna().drop(columns=[target]).copy()\n    #y = df.dropna()[target].ravel().copy()\n    \n    # w.o dropna()\n    X = df.drop(columns=[target]).copy()\n    y = df.dropna()[target].ravel().copy()\n    \n    return train_test_split(X, y, test_size=0.33, random_state=42), X, y# save trainer\nprint(\"\\nResetting train data...\")\ntrainer = c.loc[c.index!=idx].dropna().copy()\nX, y =  trainer.drop(columns=[target]), trainer[target].ravel()\nX_train, X_test, y_train, y_test = X_y_sets(trainer, target)[0]","metadata":{"execution":{"iopub.status.busy":"2023-03-23T01:45:30.943395Z","iopub.execute_input":"2023-03-23T01:45:30.943671Z","iopub.status.idle":"2023-03-23T01:45:30.972989Z","shell.execute_reply.started":"2023-03-23T01:45:30.943642Z","shell.execute_reply":"2023-03-23T01:45:30.971014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"\\nLive prediction\\n\")\n\n# choose classifier\n#clf = GradientBoostingClassifier(criterion=\"friedman_mse\", init=None, learning_rate=0.033, loss='deviance', max_depth=19, max_features=None, max_leaf_nodes=None, min_samples_leaf=60, min_samples_split=120, min_weight_fraction_leaf=0.0, n_estimators=100, random_state=42, subsample=1.0, verbose=1, warm_start=False).fit(X_train, y_train)\n#clf = RandomForestClassifier(max_depth=5, n_estimators=200, random_state=42).fit(X_train, y_train)\n#clf = ExtraTreesClassifier(n_estimators=200, random_state=42).fit(X_train, y_train)\nclf = AdaBoostClassifier(n_estimators=200, random_state=42).fit(X_train, y_train)\n#clf = MLPClassifier(alpha=1, max_iter=500).fit(X_train, y_train)\n#clf = KNeighborsClassifier().fit(X_train, y_train)\n\n\nprint()\nprint(\"Test score: \",clf.score(X_test, y_test))\nprint()\nprediction = clf.predict(use_case)[0]\nprint(f\"Prediction {target}:\",prediction)\n\n\n# print decoded prediction\nprint(\"\\nPrediction Decoded\")\ne = d[d.index == prediction]\ne","metadata":{"execution":{"iopub.status.busy":"2023-03-23T01:45:31.104808Z","iopub.execute_input":"2023-03-23T01:45:31.105048Z","iopub.status.idle":"2023-03-23T01:47:14.313132Z","shell.execute_reply.started":"2023-03-23T01:45:31.105023Z","shell.execute_reply":"2023-03-23T01:47:14.310681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if solution == e.reset_index()[target][0]:\n    print(\"Machine's prediction was correct!\")\nelse:\n    print(\"Machine's prediction was incorrect :(\")","metadata":{"execution":{"iopub.status.busy":"2023-03-23T01:47:14.315445Z","iopub.execute_input":"2023-03-23T01:47:14.315904Z","iopub.status.idle":"2023-03-23T01:47:14.325447Z","shell.execute_reply.started":"2023-03-23T01:47:14.315862Z","shell.execute_reply":"2023-03-23T01:47:14.323633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- I believe the machine's inability to predict correctly is due to a class-oriented issue in the cell above in which I define the X_y_sets function. \n- I might be seeking @jasonifier as an SME to address this issue by uniquely debugging my code. Otherwise, feel free to comment as to why setting the X variable  [(df.dropna().drop(columns=[target]).copy()] returns an empty set - Despite having X_test.info() identifies each variable to be non-null's?\n- I'll be attending to fix this as quickly as I can. ","metadata":{}},{"cell_type":"markdown","source":"# Supplementary","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n\n# classifier iteration\ndef classification_feat_importance(df_encoded):\n    \n    # iterate through each column variable as classification targets\n    for target in df_encoded.columns.values:\n        X = df_encoded.drop(columns=[target]).copy()\n        y = df_encoded[target].ravel().copy()\n\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n        \n    \n        # classifiers\n        #clf1 = GradientBoostingClassifier(criterion=\"friedman_mse\", init=None, learning_rate=0.3338, loss='deviance', max_depth=19, max_features=None, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=120, min_weight_fraction_leaf=0.0, n_estimators=500, random_state=42, subsample=1.0, verbose=1, warm_start=False).fit(X_train, y_train)\n        #clf2 = GradientBoostingClassifier(criterion=\"squared_error\", init=None, learning_rate=0.2222, loss='deviance', max_depth=19, max_features=None, max_leaf_nodes=None, min_samples_leaf=6, min_samples_split=120, min_weight_fraction_leaf=0.0, n_estimators=500, random_state=42, subsample=1.0, verbose=1, warm_start=False).fit(X_train, y_train)\n        clf3 = RandomForestClassifier(max_depth=5, n_estimators=1000, random_state=42).fit(X_train, y_train)\n        clf4 = ExtraTreesClassifier(n_estimators=200, random_state=42).fit(X_train, y_train)\n        clf5 = AdaBoostClassifier(n_estimators=8000, random_state=42).fit(X_train, y_train)\n        clf6 = MLPClassifier(alpha=1, max_iter=500).fit(X_train, y_train)\n        clf7 = KNeighborsClassifier(n_neighbors=9).fit(X_train, y_train)\n        classifiers = [\n                       #clf1, \n                       #clf2, \n                       clf3, \n                       clf4, \n                       clf5,\n                       clf6,\n                       #clf7\n                      ]\n\n        for classifier in classifiers:\n            results = []\n            results.append({\"classifier\":str(classifier).split(\"(\")[0],\"target\":target,\"test_score\":classifier.score(X_test, y_test)})\n            for i in results:\n                if target == 'verified':\n                    print(\"\\nClassifier:\",str(classifier).split(\"(\")[0],\"\\nTarget:\",target,\"\\nScore:\",classifier.score(X_test, y_test))\n        \n        test_matrix = confusion_matrix(y_test, clf.predict(X_test)) \n        results = pd.DataFrame(results)\n        \n    return results,test_matrix\n\nprint(\"To analyze which target-classifier would yield the best results: \\nUncomment (#) the code below.\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# encoding\nfrom sklearn.preprocessing import LabelEncoder\ndef encode(df):\n    lb_make = LabelEncoder()\n    columns = df.columns.values.tolist()\n    df_encoded = df[columns].copy()\n\n    # categorize/encode\n    for i in columns:\n        df_encoded[i] = lb_make.fit_transform(df[i])\n\n    # encoded\n    return df_encoded\n\n\n# encoded variable re-mapping\ndef encoding_remap(df, df_encoded, target):\n    \n    X_test = X_y_sets(df, target)[0][0]\n    \n    remap = pd.merge(df_encoded.loc[df_encoded.index.isin(X_test.index.values)][target].reset_index(),\n              df.loc[df.index.isin(X_test.index.values)][[target]].reset_index(),on=['index'])\n    \n    remap[target] = [str(remap[f'{target}_y'][i]) for i,v in remap[f'{target}_x'].items()]\n    remap['index'] = np.array([str(remap[f'{target}_x'][i]) for i,v in remap[f'{target}_x'].items()]).astype(int)\n    remap=remap[[target,'index']]\n    remap = remap.set_index('index').drop_duplicates().sort_values('index')\n    \n    return remap\n\n\n# pairplot\nimport seaborn as sns\ndef pairplot(df, target):\n    return sns.pairplot(df.sample(int(len(df/10000))),hue=target)\n    \n    \n# create X,y variables for ML\nfrom sklearn.model_selection import train_test_split\ndef X_y_sets(df, target):\n    X = df.dropna().drop(columns=[target]).copy()\n    y = df.dropna()[target].ravel().copy()\n    \n    return train_test_split(X, y, test_size=0.33, random_state=42), X, y\n\n\n# classifier iteration\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import confusion_matrix\ndef classification_feat_importance(df_encoded):\n    \n    df_encoded = df_encoded.drop(columns=['target1','target2'])\n    \n    # iterate through each column variable as classification targets\n    for target in df_encoded.columns.values:\n        X = df_encoded.dropna().drop(columns=[target]).copy()\n        y = df_encoded.dropna()[target].ravel().copy()\n\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n        \n        time.sleep(30)\n        \n        # classifiers\n        clf1 = RandomForestClassifier(max_depth=5, n_estimators=200, random_state=42).fit(X_train, y_train)\n        clf2 = AdaBoostClassifier(n_estimators=200, random_state=42).fit(X_train, y_train)\n        clf3 = ExtraTreesClassifier(n_estimators=200, random_state=42).fit(X_train, y_train)\n        clf4 = KNeighborsClassifier().fit(X_train, y_train)\n        clf5 = MLPClassifier(alpha=1, max_iter=500).fit(X_train, y_train)\n        classifiers = [\n                       clf1, \n                       clf2, \n                       clf3, \n                       clf4, \n                       clf5\n                      ]\n\n        for classifier in classifiers:\n            results = []\n            #test_matrix = confusion_matrix(y_test, clf.predict(X_test))\n            results.append({\"classifier\":str(classifier).split(\"(\")[0],\"target\":target,\"test_score\":classifier.score(X_test, y_test)})\n            print(\"Classifier:\",str(classifier).split(\"(\")[0],\"\\t\\tTarget:\",target,\"\\tScore:\",classifier.score(X_test, y_test))\n            \n    return pd.DataFrame(results)","metadata":{"execution":{"iopub.status.busy":"2023-03-23T01:38:58.845031Z","iopub.status.idle":"2023-03-23T01:38:58.845509Z","shell.execute_reply.started":"2023-03-23T01:38:58.845285Z","shell.execute_reply":"2023-03-23T01:38:58.84531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Variable Definitions & API Documentation\nData Columns in Kepler Objects of Interest Table <br>*https://exoplanetarchive.ipac.caltech.edu/docs/API_kepcandidate_columns.html\n\n\nExoplanet Archive Application Programming Interface (API) User Guide\n<br>*https://exoplanetarchive.ipac.caltech.edu/docs/program_interfaces.html","metadata":{}},{"cell_type":"code","source":"#en fin","metadata":{},"execution_count":null,"outputs":[]}]}